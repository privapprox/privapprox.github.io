<!doctype html> <html class="no-js" lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <title>Case Studies Evaluation</title> <link rel="stylesheet" type="text/css" href="http://localhost:4000/assets/css/styles_feeling_responsive.css"> <script src="http://localhost:4000/assets/js/modernizr.min.js"></script> <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script> <script> WebFont.load({ google: { families: [ 'Lato:400,700,400italic:latin', 'Volkhov::latin' ] } }); </script> <noscript> <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic%7CVolkhov' rel='stylesheet' type='text/css'> </noscript> <!-- Search Engine Optimization --> <meta name="description" content=""> <link rel="canonical" href="http://localhost:4000/case-studies/"> <!-- Facebook Open Graph --> <meta property="og:title" content="Case Studies Evaluation"> <meta property="og:description" content=""> <meta property="og:url" content="http://localhost:4000/case-studies/"> <meta property="og:locale" content="en_EN"> <meta property="og:type" content="website"> <meta property="og:site_name" content=""> <link type="text/plain" rel="author" href="http://localhost:4000/humans.txt"> </head> <body id="top-of-page" class=""> <div id="navigation" class="sticky"> <nav class="top-bar" role="navigation" data-topbar> <ul class="title-area"> <li class="name"> <h1 class="show-for-small-only"><a href="http://localhost:4000" class="icon-tree"> </a></h1> </li> <!-- Remove the class "menu-icon" to get rid of menu icon. Take out "Menu" to just have icon alone --> <li class="toggle-topbar menu-icon"><a href="#"><span>Navigation</span></a></li> </ul> <section class="top-bar-section"> <ul class="right"> <li class="divider"></li> <li><a href="http://localhost:4000/contact/">Contact</a></li> </ul> <ul class="left"> <li><a href="http://localhost:4000/">Home</a></li> <li class="divider"></li> <li><a href="http://localhost:4000/design/">PrivApprox Design</a></li> <li class="divider"></li> <li><a href="http://localhost:4000/benchmarks/">Micro-benchmarks</a></li> <li class="divider"></li> <li class="active"><a href="http://localhost:4000/case-studies/">Case-Studies</a></li> <li class="divider"></li> <li><a href="http://localhost:4000/proofs/">Proofs</a></li> <li class="divider"></li> </ul> </section> </nav> </div><!-- /#navigation --> <div class="row t30"> <div class="medium-12 columns"> <article> <header> <h1>Case Studies Evaluation</h1> </header> <div class="row"> <div class="medium-4 medium-push-8 columns"> <div class="panel radius"> <p id="toc"><strong>Table of Contents</strong></p> <ul id="markdown-toc"> <li><a href="#experimental-setup" id="markdown-toc-experimental-setup">Experimental Setup</a></li> <li><a href="#results" id="markdown-toc-results">Results</a> <ul> <li><a href="#scalability" id="markdown-toc-scalability">Scalability</a></li> <li><a href="#network-bandwidth-and-latency" id="markdown-toc-network-bandwidth-and-latency">Network Bandwidth and Latency</a></li> <li><a href="#utility-and-privacy" id="markdown-toc-utility-and-privacy">Utility and Privacy</a></li> <li><a href="#historical-analytics" id="markdown-toc-historical-analytics">Historical Analytics</a></li> </ul> </li> </ul> </div> </div><!-- /.medium-4.columns --> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$','$'] ], displayMath: [ ['$$','$$'] ], processEscapes: true, } }); </script> <script src="/assets/js/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> <div class="medium-8 medium-pull-4 columns"> <p>We next present our experience about using PrivApprox in the following two case studies: <em>(i)</em> New York City (NYC) taxi ride, and <em>(ii)</em> household electricity consumption.</p> <h2 id="experimental-setup">Experimental Setup</h2> <p><strong>Cluster setup.</strong> We used a cluster of $44$ nodes connected via a Gigabit Ethernet. Each node contains 2 Intel Xeon quad-core CPUs and 8 GB of RAM running Debian 5.0 with Linux kernel 2.6.26. We deployed two proxies with Apache Kafka, each of which consists of $4$ Kafka broker nodes and $3$ Zookeeper nodes. We used $20$ nodes to deploy Apache Flink as the aggregator. In addition, we employed the remaining $10$ nodes to replay the datasets to generate data streams for evaluating our PrivApprox system.</p> </div> <div class="medium-12 medium-pull-12 columns"> <p><strong>Datasets.</strong> For the first case study, we used the <em>NYC Taxi Ride</em> dataset from the DEBS 2015 Grand Challenge~\cite{nyc-taxi-dataset}. The dataset consists of the itinerary information of all rides across $10,000$ taxies in New York City in 2013. %a wide area of $150\ km \times 150\ km$ around For the second case study, we used the <em>Household Electricity Consumption</em> dataset~\cite{electricity-dataset}. This dataset contains electricity usage (Kwh) measured every 30 minutes for one year by smart meters. %This dataset is small as it contains electricity usage of only $31$ households in Australia. Nevertheless, we enlarged the dataset by duplicating it $5,000$ times. We notice that, duplicating the dataset may create bias. Therefore, for the second dataset, we did not measure the output accuracy and privacy level; instead, we used it to measure the throughput/latency and bandwidth overheads.</p> <p><strong>Queries.</strong> For the NYC taxi ride case-study, we created a query: “<em>What is the distance distribution of taxi trips in New York?</em>”. We defined the query answer with $11$ buckets as follows: [0 1) mile, [1, 2) miles, [2, 3) miles, [3, 4) miles, [4, 5) miles, [5, 6) miles, [6, 7) miles, [7, 8) miles, [8, 9) miles, [9, 10) miles, and [10, $+\infty$) miles. %We extracted the raw data set to get the important fields in each record for the analysis including timestamp, taxi ID, and distances.</p> <p>For the second case-study, we defined a query to analyze the electricity usage distribution of households over the past 30 minutes. The query answer format is as follows: [0, 0.5] Kwh, (0.5, 1] Kwh, (1, 1.5] Kwh, (1.5, 2] Kwh, (2, 2.5] Kwh, and (2.5, 3] Kwh. % We extracted from the dataset the information about timestamp, household ID, and electricity use.</p> <p><strong>Evaluation metrics.</strong> We evaluated our system using four key metrics: throughput, latency, utility, and privacy level. <em>Throughput</em> is defined as the number of data items processed per second, and <em>latency</em> is defined as the total amount of time required to process a certain dataset. <em>Utility</em> is the accuracy loss defined as $| \frac{estimate - exact}{exact} |$, where $estimate$ and $exact$ are the query results produced by applying PrivApprox and the native computation, respectively. Finally, <em>privacy level</em> ((\epsilon_{zk})) is calculated using equation~\ref{eq:ezk}.<br /> For all measurements, we report the average over $10$ runs.</p> <h2 id="results">Results</h2> <h3 id="scalability">Scalability</h3> <p>\label{subsec:cs-scalability} We measured the scalability of the two main system components: proxies and the aggregator. We first measured the throughput of proxies with various numbers of CPU cores (scale-up) and different numbers of nodes (scale-out). This experiment was conducted on a cluster of $4$ nodes. Figure~\ref{fig:throughput-proxies-aggregator} (a) shows that, as expected, the throughput at proxies scales quite well with the number of CPU cores and nodes. In the NYC Taxi case-study, with $2$ cores, the throughput of each proxy is $512,348$ answers/sec, and with $8$ cores (1 node) the throughput is $1,192,903$ answers/sec; whereas, with a cluster of $4$ nodes each with $8$ cores, the throughput of each proxy reaches $2,539,715$ answers/sec. In the household electricity case-study, the proxies achieve relatively a higher throughput compared because the message size is smaller than in the NYC Taxi case-study.</p> <p>We next measured the throughput at the aggregator. This experiment was conducted with 44 nodes including $20$ nodes for deploying the aggregator, $7$ nodes for each proxy, and $10$ nodes for replaying datasets. Figure~\ref{fig:throughput-proxies-aggregator} (b) depicts that the aggregator also scales quite well when the number of nodes for aggregator increases. The throughput of aggregator, however, is much lower than the throughput of proxies due to the relatively expensive {\tt join} operation and the analytical computation at the aggregator. We notice that the throughput of the aggregator in the household electricity case study does not significantly improve in comparison to the first case study. This is because the difference in the size of messages between the two case studies does not affect much on the performance of the {\tt join} operation and the analytical computation.</p> <h3 id="network-bandwidth-and-latency">Network Bandwidth and Latency</h3> <p>\label{subsec:cs-varying-clients}</p> <p>Next, we conducted the experiment to measure the network bandwidth usage. By leveraging the sampling mechanism at clients, our system reduces network traffic significantly. Figure~\ref{fig:bandwidth-latency} (a) shows the total network traffic transferred from clients to proxies with different sampling fractions. In the first case study, with the sampling fraction of $60$\%, \projecttitle can reduce the network traffic by $1.62\times$; whereas in the second case study, the reduction is $1.58\times$.</p> <p>Beside the benefit of saving network bandwidth, \projecttitle achieves also lower latency in processing query answers by leveraging approximate computation. To evaluate this advantage, we measured the effect of sampling fractions on the latency of processing query answers. Figure~\ref{fig:bandwidth-latency} (b) depicts the latency with different sampling fractions at clients. For the first case-study, with the sampling fraction of $60$\%, the latency is $1.68\times$ lower than the execution without sampling; whereas, in the second case-study this value is $1.66 \times$ lower than the execution without sampling.</p> <h3 id="utility-and-privacy">Utility and Privacy</h3> <p>\label{subsec:cs-sampling-randomizing} %To measure the utility and privacy level with different sampling fractions at clients. %For this experiment, we used the first dataset only (see $\S$\ref{subsec:experimental-setup} for the reason). %For this experiment, we used the NYC Taxi dataset.<br /> %Figure~\ref{fig:utility-privacy-taxi} (a) and Figure~\ref{fig:utility-privacy-taxi} (b) show the utility and the privacy level, respectively, with different sampling and randomization parameters. Figure~\ref{fig:utility-privacy-taxi} (a)(b)(c) show the utility, the privacy level, and the trade-off between them, respectively, with different sampling and randomization parameters. The randomization parameters $p$ and $q$ are varied in the range of (0, 1), and the sampling parameter $s$ is calculated using Equation~\ref{eq:ezk}. Here, we show results only for NYC Taxi dataset. As the sampling parameter $s$ and the first randomization parameter $p$ increase, the utility of query results improves (i.e., accuracy loss gets smaller) whereas the privacy guarantee gets weaker (i.e., privacy level gets higher). Since the New York taxi dataset is diverse, the accuracy loss and the privacy level change in a non-linear fashion with different sampling fractions and randomization parameters. Interestingly, the accuracy loss does not always decrease as the second randomization parameter $q$ increases. The accuracy loss gets smaller when $q = 0.3$. This is due to the fact that the faction of truthful “Yes” answers in the dataset is $33.57$\% (close to $q=0.3$).</p> <h3 id="historical-analytics">Historical Analytics</h3> <p>\label{subsec:cs-historical-analytics} To analyze the performance of \projecttitle for historical analytics, we executed the queries on the datasets stored at the aggregator. Figure~\ref{fig:historical-analysis} (a) (b) present the latency and throughput, respectively, of processing historical datasets with different sampling fractions. We can achieve a speedup of $1.86 \times$ over native execution in historical analytics by setting the sampling fraction to $60$\%.</p> <p>We also measured the accuracy loss when the approximate computation was applied (for the NYC Taxi case-study). Figure~\ref{fig:historical-analysis} (c) shows the accuracy loss in processing historical with different sampling fractions. With the sampling fraction of $60$\%, the accuracy loss is only less than $1$\%.</p> </div></div> </article> </div><!-- /.medium-12.columns --> </div><!-- /.row --> <div id="up-to-top" class="row"> <div class="small-12 columns" style="text-align: right;"> <a class="iconfont" href="#top-of-page">&#xf108;</a> </div><!-- /.small-12.columns --> </div><!-- /.row --> <footer id="footer-content" class="bg-grau"> <div id="footer"> <div class="row"> <div class="medium-6 large-5 columns"> <h5 class="shadow-black">About This Site</h5> <p class="shadow-black"> <a href="http://localhost:4000/info/">More ›</a> </p> </div><!-- /.large-6.columns --> <div class="small-6 medium-3 large-3 large-offset-1 columns"> <h5 class="shadow-black">Services</h5> <ul class="no-bullet shadow-black"> <li > <a href="http://localhost:4000" title=""></a> </li> <li > <a href="http://localhost:4000/contact/" title="Contact">Contact</a> </li> </ul> </div><!-- /.large-4.columns --> <div class="small-6 medium-3 large-3 columns"> <ul class="no-bullet shadow-black"> </ul> </div><!-- /.large-3.columns --> </div><!-- /.row --> </div><!-- /#footer --> <div id="subfooter"> <nav class="row"> <section id="subfooter-left" class="small-12 medium-6 columns credits"> </section> <section id="subfooter-right" class="small-12 medium-6 columns"> <ul class="inline-list social-icons"> <li><a href="https://bitbucket.org/lequocdo/privapprox" target="_blank" class="icon-github" title="Code for PrivApprox evaluation"></a></li> </ul> </section> </nav> </div><!-- /#subfooter --> </footer> <script src="http://localhost:4000/assets/js/javascript.min.js"></script> </body> </html>
